{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pascal segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Pascal VOC challenge is a very popular dataset for building and evaluating algorithms for image classification, object detection, and segmentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classes:\n",
    "`background`, `aeroplane`, `bicycle`, `bird`, `boat`, `bottle`, `bus`, `car`, `cat`, `chair`, `cow`, `diningtable`, `dog`, `horse`, `motorbike`, `person`, `pottedplant`, `sheep`, `sofa`, `train`, `tvmonitor`\n",
    "\n",
    "255 is the ignore label that marks pixels excluded from learning and\n",
    "evaluation by the PASCAL VOC ground truth."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Necessary imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import PIL\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "sys.path.append('..')\n",
    "from batchflow import B, V, F, R, P, W\n",
    "from batchflow.opensets import PascalSegmentation\n",
    "from batchflow.models.torch import TorchModel, UNet, ResUNet\n",
    "from batchflow.models.metrics import ClassificationMetrics\n",
    "\n",
    "plt.style.use('seaborn-poster')\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_data(label, prediction):\n",
    "    _, ax = plt.subplots(1, 2, figsize=(15, 15))\n",
    "    ax[0].set_title('Mask')\n",
    "    ax[0].imshow(label)\n",
    "    ax[0].grid()\n",
    "    ax[1].set_title('Prediction')\n",
    "    ax[1].imshow(prediction)\n",
    "    ax[1].grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = PascalSegmentation(bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We should construct batch and get images.\n",
    "batch = ds.train.p.next_batch(16)\n",
    "images = batch.images\n",
    "labels = batch.labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Define training pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 22\n",
    "model_config = {\n",
    "    'inputs/targets/classes': NUM_CLASSES,\n",
    "    'body/encoder/num_stages': 4,\n",
    "    'body/decoder/blocks/filters': [512, 256, 128, 64],\n",
    "    'body/encoder/blocks/filters': [64, 128, 256, 512],\n",
    "    'body/embedding/filters': 512,\n",
    "    'head': dict(layout='c', filters=NUM_CLASSES, kernel_size=1),\n",
    "\n",
    "    'optimizer': ('Adam', {'lr': 0.001}),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define constants\n",
    "BATCH_SIZE = 50\n",
    "N_EPOCHS = 200\n",
    "SIZE = (160, 160)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_mask(x):\n",
    "    x = np.squeeze(x)\n",
    "    np.place(x, x==255, 21)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define actions for training\n",
    "train_ppl = (ds.train.p\n",
    "    .init_model('dynamic', UNet, 'model', config=model_config)\n",
    "    .init_variable('loss', [])\n",
    "    .resize(size=SIZE, src='images', dst='images')\n",
    "    .resize(size=SIZE, src='labels', dst='labels')\n",
    "    .to_array(channels='first', src='images', dst='images')\n",
    "    .to_array(channels='first', src='labels', dst='labels')\n",
    "    .apply_transform_all(src='labels', dst='labels', func=process_mask)\n",
    "    .train_model('model', B('images'), B('labels'), fetches='loss', save_to=V('loss', mode='a'))\n",
    "    .run_later(BATCH_SIZE, n_epochs=N_EPOCHS, drop_last=True, shuffle=42, bar='n')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we will run it\n",
    "train_ppl.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_ppl.v('loss')[:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. ... and test pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define actions for test\n",
    "test_ppl = (ds.test.p\n",
    "    .import_model('model', train_ppl)\n",
    "    .resize(size=SIZE, src='images', dst='images')\n",
    "    .resize(size=SIZE, src='labels', dst='labels')\n",
    "    .to_array(channels='first', src='images', dst='images')\n",
    "    .to_array(channels='first', src='labels', dst='labels')\n",
    "    .apply_transform_all(src='labels', dst='labels', func=process_mask)\n",
    "    .predict_model('model', B('images'), fetches='predictions', save_to=B('predictions'))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 Calculate metrics for one batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = test_ppl.next_batch(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = batch.labels\n",
    "predictions = np.argmax(batch.predictions, axis=1)\n",
    "\n",
    "draw_data(labels[4], predictions[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will use f1 score form other library\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "f1_score_wh_zeros = f1_score(labels.ravel(), predictions.ravel().astype(int),\n",
    "                             labels=np.arange(NUM_CLASSES), average=None)\n",
    "\n",
    "print(\"F1 score for each class:\\n\", f1_score_wh_zeros)\n",
    "\n",
    "print('\\n\\nResulted f1: ', np.mean(f1_score_wh_zeros[f1_score_wh_zeros != 0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2. Predictions for all test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define actions for test without gather_metrics\n",
    "test_ppl = (ds.test.p\n",
    "    .import_model('model', train_ppl)\n",
    "    .init_variable('targets', [])\n",
    "    .init_variable('predictions', [])\n",
    "    .resize(size=SIZE, src='images', dst='images')\n",
    "    .resize(size=SIZE, src='labels', dst='labels')\n",
    "    .to_array(channels='first', src='images', dst='images')\n",
    "    .to_array(channels='first', src='labels', dst='labels')\n",
    "    .apply_transform_all(src='labels', dst='labels', func=process_mask)\n",
    "    .predict_model('model', B('images'), fetches='predictions', save_to=V('predictions', mode='a'))\n",
    "    .update(V('targets', mode='a'), B('labels'))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ppl.run(4, drop_last=False, bar='n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(test_ppl.v('targets')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting a labels and predictions from pipeline\n",
    "labels = np.array(test_ppl.v('targets'))\n",
    "print('labels.shape: ', labels.shape)\n",
    "\n",
    "print('labels.shape after concatenation: ', np.concatenate(labels).shape)\n",
    "\n",
    "labels = np.concatenate(np.concatenate(labels))\n",
    "\n",
    "predictions = np.array(test_ppl.v('predictions'))\n",
    "predictions = np.concatenate(predictions)\n",
    "print('predictions shape after concatenation: ', predictions.shape)\n",
    "\n",
    "predictions = np.argmax(predictions, axis=1)\n",
    "print('predictions shape after argmax: ', predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score_wh_zeros = f1_score(labels.ravel(), predictions.ravel().astype(int),\n",
    "                             labels=np.arange(NUM_CLASSES), average=None)\n",
    "\n",
    "print(\"F1 score for each class:\\n\", f1_score_wh_zeros)\n",
    "\n",
    "print('\\n\\nResulted f1: ', np.mean(f1_score_wh_zeros[f1_score_wh_zeros != 0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save model from pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ppl.save_model_now('model', 'my_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get model from pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model = train_ppl.m('model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is still batchflow model\n",
    "print(my_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save torch model from batchflow model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model.save('my_model_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#how to get pytorch model from batchflow\n",
    "pure_torch = my_model.model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "load_config = {\n",
    "    'device': 'gpu:0',\n",
    "    'load/path': './my_model'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_ppl = (ds.test.p\n",
    "    #here we are gonna load the model\n",
    "    .init_model('dynamic', UNet, 'model', config=load_config)\n",
    "    .init_variable('metrics', None)\n",
    "    .init_variable('targets', [])\n",
    "    .init_variable('preds', [])\n",
    "    .resize(size=SIZE, src='images', dst='images')\n",
    "    .resize(size=SIZE, src='labels', dst='labels')\n",
    "    .to_array(channels='first', src='images', dst='images')\n",
    "    .to_array(channels='first', src='labels', dst='labels')\n",
    "    .update(V('targets', mode='a'), B('labels'))\n",
    "    .apply_transform_all(src='labels', dst='labels', func=process_mask)\n",
    "    .predict_model('model', B('images'), fetches='predictions', save_to=B('predictions'))\n",
    "    .update(V('preds',mode='a'), B('predictions')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check whether the model loaded or not\n",
    "batch = load_ppl.next_batch(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = batch.labels\n",
    "predictions = np.argmax(batch.predictions, axis=1)\n",
    "\n",
    "draw_data(labels[4], predictions[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task:\n",
    "\n",
    "Try to modify the model and training process to get better f1 score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What you can change?\n",
    "For example, you can add additional keys into dictionary and then try to vary them:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "model_config = {\n",
    "                'inputs/targets/classes': NUM_CLASSES,\n",
    "                'body/encoder/num_stages': 4,\n",
    "                'body/decoder/blocks/filters': [128, 64, 64, 32],\n",
    "                'body/encoder/blocks/filters': [32, 64, 64, 128],\n",
    "                'body/embedding/filters': 128,\n",
    "                'head': dict(layout='c', filters=NUM_CLASSES, kernel_size=1),\n",
    "    \n",
    "                'optimizer': ('Adam', {'lr': 0.001}),\n",
    "            }\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
